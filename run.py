import os
import parsel
from utils.common_tools import get_html, decrypt_text

"""è§£æå°è¯´ä¸»é¡µï¼Œæå–åŸºæœ¬ä¿¡æ¯å’Œç« èŠ‚ç›®å½•"""
def parse_main_page(url):
    html = get_html(url)
    if not html:
        print("[x] ä¸»é¡µé¢è¯·æ±‚å¤±è´¥")
        return None, [], []
    selector = parsel.Selector(html)
    # æå–åŸºæœ¬ä¿¡æ¯
    book_title = selector.css('.info-name h1::text').get(default='æœªçŸ¥æ ‡é¢˜').strip()
    author_name = selector.css('.author-name-text::text').get(default='æœªçŸ¥ä½œè€…').strip()
    chapter_count = selector.css('.page-directory-header h3::text').get(default='0').strip()
    # word_count_info = selector.css('.info-count-word span::text').getall() # å°è¯´å­—æ•°
    # book_description = selector.css('.page-abstract-content p::text').get(default='').strip() # å°è¯´ç®€ä»‹
    tags = selector.css('.info-label span::text').getall()
    # æå–ç« èŠ‚ä¿¡æ¯
    chapter_titles = selector.css('.chapter-item-title::text').getall()
    chapter_hrefs = selector.css('.chapter-item-title::attr(href)').getall()
    # æå–æœ€è¿‘æ›´æ–°ä¿¡æ¯
    last_update_title = selector.css('.info-last-title::text').getall()[1]
    last_update_time = selector.css('.info-last-time::text').get(default='').strip()
    # è¾“å‡ºæ‘˜è¦ä¿¡æ¯
    print(f"ğŸ“˜ å°è¯´ï¼šã€Š{book_title}ã€‹ by {author_name}")
    print(f"ğŸ“– å…± {chapter_count} ç« ï¼›æ ‡ç­¾ï¼š{'ã€'.join(tags)}")
    print(f"ğŸ•˜ æœ€è¿‘æ›´æ–°ï¼š{last_update_title} Â· {last_update_time}")
    return book_title, chapter_titles, chapter_hrefs[1:]  # å¯é€‰è·³è¿‡ç¬¬ä¸€ä¸ªï¼ˆå¦‚ä¸ºå¼•å¯¼/ç›®å½•ï¼‰


"""ä¸‹è½½å¹¶è§£å¯†ç« èŠ‚"""
def download_chapters(book_title, titles, urls):
    output_dir = "output"
    os.makedirs(output_dir, exist_ok=True)  # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    file_path = os.path.join(output_dir, f"{book_title}.txt")
    print(f"ğŸ å¼€å§‹ä¸‹è½½å°è¯´ã€Š{book_title}ã€‹")
    with open(file_path, "w", encoding="utf-8") as f:
        for title, link in zip(titles, urls):
            full_url = 'https://fanqienovel.com' + link
            html = get_html(full_url)
            if not html:
                print(f"[x] ç« èŠ‚ã€Š{title}ã€‹è¯·æ±‚å¤±è´¥ï¼Œå·²è·³è¿‡")
                continue
            selector = parsel.Selector(html)
            print(selector)
            print(full_url)
            content_list = selector.css('.muye-reader-content-16 p::text').getall()
            raw_text = '\n'.join(content_list)
            decrypted_text = decrypt_text(raw_text)
            f.write(f"\n\n{title}\n\n")
            f.write(decrypted_text)
            print(f"âœ… å·²ä¸‹è½½ï¼š{title}")
    print(f"ğŸ‰ å·²ä¿å­˜è‡³ï¼š{file_path}")


if __name__ == "__main__":
    book_id= input("è¯·è¾“å…¥å°è¯´IDï¼š").strip()
    # âœ… è®¾ç½®å°è¯´ä¸»é¡µé¢ URL
    novel_url = f"https://fanqienovel.com/page/{book_id}"
    # âœ… è§£æä¸»é¡µé¢ï¼Œæå–ç« èŠ‚ä¿¡æ¯
    result = parse_main_page(novel_url)
    # åˆ¤æ–­å°è¯´é¡µé¢æ˜¯å¦è§£ææˆåŠŸ
    if not result:
        print("[x] å°è¯´é¡µé¢è§£æå¤±è´¥ï¼Œç¨‹åºç»ˆæ­¢ã€‚")
    else:
        book_title, chapter_titles, chapter_urls = result
        for i, (title, url) in enumerate(zip(chapter_titles, chapter_urls), start=1):
            print(f"{i}. {title} - {url}")
        while True:
            user_input = input("è¯·è¾“å…¥è¦ä¸‹è½½çš„ç« èŠ‚èŒƒå›´ï¼ˆå¦‚ 1-220 æˆ– allï¼‰ï¼š").strip().lower()
            if user_input == "all":
                download_chapters(book_title, chapter_titles, chapter_urls)
                break
            elif "-" in user_input:
                try:
                    start_str, end_str = user_input.split("-")
                    start_idx = int(start_str) - 1  # è½¬æ¢ä¸ºåˆ—è¡¨ä¸‹æ ‡
                    end_idx = int(end_str)  # åŒ…å«è¯¥ç« èŠ‚

                    if 0 <= start_idx < end_idx <= len(chapter_urls):
                        selected_titles = chapter_titles[start_idx:end_idx]
                        selected_urls = chapter_urls[start_idx:end_idx]
                        download_chapters(book_title, selected_titles, selected_urls)
                        break
                    else:
                        print(f"è¯·è¾“å…¥æœ‰æ•ˆèŒƒå›´ï¼ˆ1-{len(chapter_urls)}ï¼‰")
                except ValueError:
                    print("æ ¼å¼é”™è¯¯ï¼Œè¯·è¾“å…¥ç±»ä¼¼ '1-220' çš„èŒƒå›´")
            else:
                print("è¾“å…¥æ— æ•ˆï¼Œè¯·è¾“å…¥ '1-220' æˆ– 'all'")

    input("æŒ‰ä»»æ„é”®ç»“æŸ...")
